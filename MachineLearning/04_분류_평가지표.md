# 모델평가
- 데이터셋 분리
- 모델 생성
- 모델 학습
- 예측
- **평가**

## 분류와 회귀의 평가방법
### 분류 평가 지표
1. 정확도 (Accuracy)
1. 정밀도 (Precision)  :불균형 데이터셋 평가지표 - 예측한것중에 몇개를 맞췄나
1. 재현률/민감도 (Recall):불균형 데이터셋 평가지표 - 실제중 몇개를 맞췄나
1. F1점수 (F1 Score)  :불균형 데이터셋 평가지표 - 정밀도와 재현율의 조화평균
1. PR Curve, AP      :불균형 데이터셋 평가지표 - PR Curve: 정밀도와 재현율 관련 그래프, AP: 그래프를 숫자로 표현
1. ROC, AUC          :불균형 데이터셋 평가지표 - 그래프를 값으로 표현

### 회귀 평가방법
1. MSE (Mean Squared Error)
1. RMSE (Root Mean Squared Error)
1. 결정계수($R^2$)

### sckit-learn 평가함수 
- sklearn.metrics 모듈을 통해 제공

# 분류(Classification) 평가 기준
## 용어
- ### 이진 분류에서 양성과 음성
    - 양성: 예측하려는(찾으려는) 대상
    - 음성: 예측하려는 대상이 아닌 것
        
## 정확도 (Accuracy)

정확도 (Accuracy) = {맞게 예측한 건수} / {전체 예측 건수}
- 전체 예측 한 것중 맞게 예측한 비율로 평가한다.
- `accuracy_score(모델예측값, 정답)`

### Accuracy 평가지표의 문제
- 불균형 데이터의 경우 정확한 평가지표가 될 수 없다.